{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"crop.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNJVkJ+DbY+VtuT5GF65b7e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XDzZU3f8MDqR"},"source":["# **Crop**"]},{"cell_type":"code","metadata":{"id":"4nw5lkpFLPNj"},"source":["import cv2\n","import sys\n","import os.path\n","import glob\n","\n","output = glob.glob('/content/drive/Shareddrives/인수 플젝/webtoon_crop/*/*.png')\n","\n","def make_file_name(filename):\n","    folder = filename.split('/')[-2]\n","    file = filename.split('/')[-1].split('.')[0]\n","    return folder + \"_\" + file\n","\n","def detect(filename, cascade_file = \"/content/drive/Shareddrives/인수 플젝/face-detected_2/lbpcascade_animeface.xml\"):\n","    if not os.path.isfile(cascade_file):\n","        raise RuntimeError(\"%s: not found\" % cascade_file)\n","\n","    cascade = cv2.CascadeClassifier(cascade_file)\n","    image = cv2.imread(filename, cv2.IMREAD_COLOR)\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    gray = cv2.equalizeHist(gray)\n","    \n","    faces = cascade.detectMultiScale(gray,\n","                                     scaleFactor = 1.1,\n","                                     minNeighbors = 3,\n","                                     minSize = (3, 3))\n","    for index, (x, y, w, h) in enumerate(faces):\n","      if w != h:\n","        print(filename)\n","        continue\n","      cv2.imwrite(make_file_name(filename)+ \"_\" + str(index) + \".png\", image[y: y+h, x: x+w, :])\n","\n","for filename in output:\n","    detect(filename)\n","   \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YeeSaPtBMCtj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3D-22HYPLdbw"},"source":["# **UpScaling**\n"]},{"cell_type":"code","metadata":{"id":"iBt-Sf7qLua6"},"source":["from zipfile import ZipFile\n","file_name = '/content/drive/Shareddrives/인수 플젝/Waifu2x-master.zip'\n","\n","with ZipFile(file_name, 'r') as zip:\n","  zip.extractall()\n","  print('Done')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FSyrk4E7LviJ"},"source":["import os\n","import glob\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from utils.prepare_images import *\n","from Models import *\n","from torchvision.utils import save_image\n","\n","model_cran_v2 = CARN_V2(color_channels=3, mid_channels=64, conv=nn.Conv2d,\n","                        single_conv_size=3, single_conv_group=1,\n","                        scale=2, activation=nn.LeakyReLU(0.1),\n","                        SEBlock=True, repeat_blocks=3, atrous=(1, 1, 1))\n","                        \n","model_cran_v2 = network_to_half(model_cran_v2)\n","checkpoint = \"/content/drive/Shareddrives/인수 플젝/model_check_points/CRAN_V2/CARN_model_checkpoint.pt\"\n","model_cran_v2.load_state_dict(torch.load(checkpoint, 'cpu'))\n","# if use GPU, then comment out the next line so it can use fp16. \n","model_cran_v2 = model_cran_v2.float() \n","\n","def upscaling(img_dir):\n","  \n","  img_name = img_dir.split('/')[-1]\n","  #demo_img = image\n","  img = Image.open(img_dir).convert(\"RGB\")\n","\n","  if img.size[0]<128:\n","    return\n","  elif img.size[0]>256:\n","    print(img_name)\n","    res = img.resize((256,256))\n","    res.save(\"/content/drive/Shareddrives/인수 플젝/img512/\"+img_name)\n","  else:\n","    print(img_name)\n","    tmp = img.resize((128,128))\n","    #tmp = to_tensor(tmp).unsqueeze(0) \n","\n","    img_splitter = ImageSplitter(seg_size=64, scale_factor=2, boarder_pad_size=3)\n","    img_patches = img_splitter.split_img_tensor(tmp, scale_method=None, img_pad=0)\n","    with torch.no_grad():\n","        out = [model_cran_v2(i) for i in img_patches]\n","    res = img_splitter.merge_img_tensor(out)\n","    save_image(res,\"/content/drive/Shareddrives/인수 플젝/img512/\"+img_name)\n","  #final = torch.cat([img_t, img_upscale])\n","  #save_image(final, 'out.png', nrow=2)\n","  #print(img_upscale.shape,final.shape)\n","  #plt.imshow(img_upscale[0].permute(1, 2, 0))\n","  #plt.show()\n","  \n","\n","for i in glob.glob(\"/content/drive/Shareddrives/인수 플젝/face-detected_2/*.png\"):\n","  upscaling(i)\n","# image = \"input_image.png\"\n","\n","# upscaling(image)"],"execution_count":null,"outputs":[]}]}